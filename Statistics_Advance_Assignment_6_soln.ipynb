{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ea9815",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb20910",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means of three or more groups or conditions to determine if there are statistically significant differences among them. ANOVA relies on several assumptions, and violations of these assumptions can impact the validity of the results. The main assumptions of ANOVA are:\n",
    "\n",
    "Independence: The observations within each group or condition must be independent of each other. This means that the data points in one group should not be influenced by or related to the data points in other groups. Violations of this assumption can occur when there is a lack of independence due to, for example, repeated measures on the same subjects or a nested design.\n",
    "\n",
    "Example of a violation: In a repeated measures ANOVA, where the same participants are measured under multiple conditions, the assumption of independence is violated because the observations within each subject are not independent.\n",
    "\n",
    "Normality: The data within each group or condition should follow a normal distribution. Normality implies that the data points are symmetrically distributed around the mean, and the tails of the distribution are not too heavy or too light. Violations of this assumption can lead to inaccurate p-values and confidence intervals.\n",
    "\n",
    "Example of a violation: If the data in one or more groups are significantly skewed or have heavy tails, it may violate the normality assumption. For instance, if you're comparing the test scores of students and the scores in one group are highly skewed, ANOVA assumptions may not hold.\n",
    "\n",
    "Homogeneity of Variance (Homoscedasticity): The variances of the different groups or conditions should be approximately equal. In other words, the spread or dispersion of data should be similar across groups. Violations of this assumption can affect the F-test's validity, which is used in ANOVA to compare group variances.\n",
    "\n",
    "Example of a violation: If you're comparing the yields of different fertilizer treatments on plants, and one treatment group shows much greater variability in yields compared to others, it violates the homogeneity of variance assumption.\n",
    "\n",
    "Interval or Ratio Data: ANOVA assumes that the dependent variable is measured on an interval or ratio scale. This means that the distances between values are meaningful and consistent across the entire range of the scale. ANOVA is not appropriate for categorical or ordinal data.\n",
    "\n",
    "Example of a violation: Using ANOVA to compare the performance of employees based on their job titles (e.g., manager, supervisor, clerk) would be inappropriate if the job titles are nominal categories.\n",
    "\n",
    "When these assumptions are violated, the results of ANOVA may not be reliable. Common methods to address violations include transformation of the data (e.g., log transformation), using non-parametric alternatives (e.g., Kruskal-Wallis test), or employing robust methods that are less sensitive to violations.\n",
    "\n",
    "It's essential to assess these assumptions before conducting ANOVA and, if necessary, take appropriate steps to address violations to ensure the validity of the results and the reliability of conclusions drawn from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42eb443",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a70e605",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means among three or more groups or conditions. There are three main types of ANOVA, each suited for different situations:\n",
    "\n",
    "One-Way ANOVA:\n",
    "\n",
    "Situation: One-Way ANOVA is used when you have one independent variable (factor) with three or more levels or groups, and you want to determine if there are statistically significant differences in the means of a continuous dependent variable across these groups.\n",
    "Example: You want to compare the mean test scores of students who have been taught by three different teachers (Teacher A, Teacher B, and Teacher C) to see if there is a statistically significant difference in their teaching effectiveness.\n",
    "Two-Way ANOVA:\n",
    "\n",
    "Situation: Two-Way ANOVA is used when you have two independent variables (factors), and you want to analyze how they interact to influence a continuous dependent variable. It assesses the main effects of each independent variable and their interaction effect.\n",
    "Example: You are studying the effects of both gender (male, female) and a new teaching method (Method A, Method B) on student test scores. Two-Way ANOVA would help determine if there are significant main effects of gender, teaching method, and if there is an interaction effect between them.\n",
    "Repeated Measures ANOVA:\n",
    "\n",
    "Situation: Repeated Measures ANOVA is used when you have one or more independent variables, and the same subjects are measured under multiple conditions or time points. It is used to assess within-subjects effects and how they change over time or conditions.\n",
    "Example: You are measuring the blood pressure of the same group of individuals before and after they undergo three different exercise regimes (running, cycling, swimming). Repeated Measures ANOVA would help determine if there is a significant change in blood pressure across different exercise types while accounting for the repeated measurements within each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ac3e7",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3642d2ea",
   "metadata": {},
   "source": [
    "The partitioning of variance in Analysis of Variance (ANOVA) is a fundamental concept that helps in understanding how the total variation in the data is divided into different components, each of which contributes to the overall variability. Understanding this concept is crucial because it provides insights into the sources of variation in a dataset and helps us assess the significance of these sources. It is a key aspect of ANOVA's ability to determine whether there are statistically significant differences among groups or conditions.\n",
    "\n",
    "In ANOVA, the total variation in the data (Total Sum of Squares, or SST) is partitioned into three main components:\n",
    "\n",
    "Between-Groups Variation (Sum of Squares Between, SSB): This component measures the variability among the group means. It quantifies how much the means of the different groups or conditions differ from each other. Large between-groups variation suggests that there are significant differences among the groups being compared.\n",
    "\n",
    "Within-Groups Variation (Sum of Squares Within, SSW): This component measures the variability within each group or condition. It quantifies the variation that is not explained by differences among the group means but rather represents the random variation or noise within each group. Smaller within-groups variation indicates that the data points within each group are more consistent and that the group means are representative.\n",
    "\n",
    "Error (or Residual) Variation: This is similar to within-groups variation and represents the unexplained variability in the data. It accounts for factors other than the ones included in the ANOVA model. It's often considered as part of the within-groups variation and is sometimes used in calculating the F-statistic for hypothesis testing.\n",
    "\n",
    "The key idea in ANOVA is to compare the between-groups variation to the within-groups variation. If the between-groups variation is significantly larger than the within-groups variation (as assessed through the F-statistic), it suggests that there are statistically significant differences among the groups or conditions being compared. In other words, the means of the groups are not equal.\n",
    "\n",
    "Understanding the partitioning of variance helps researchers:\n",
    "\n",
    "Assess the significance of group differences: By comparing the relative magnitudes of between-groups and within-groups variations, ANOVA determines if the observed differences are likely due to real effects or if they could have occurred by chance.\n",
    "\n",
    "Identify sources of variation: It helps identify whether the variation in the data is primarily due to differences among groups or if it's more attributable to random noise within each group.\n",
    "\n",
    "Interpret the results: Understanding the partitioning of variance allows researchers to explain why group means differ and to draw meaningful conclusions from their data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df8b11",
   "metadata": {},
   "source": [
    "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b704fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 855.7333333333333\n",
      "SSE: 180.13333333333344\n",
      "SSR: 675.5999999999999\n",
      "F-statistic: 1.5997631734754305\n",
      "p-value: 0.24216264370065477\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data\n",
    "group_A = [45, 50, 55, 60, 65]\n",
    "group_B = [55, 58, 63, 68, 72]\n",
    "group_C = [48, 52, 57, 62, 67]\n",
    "\n",
    "# Combine data from all groups\n",
    "data = np.concatenate([group_A, group_B, group_C])\n",
    "\n",
    "# Calculate the overall mean (grand mean)\n",
    "grand_mean = np.mean(data)\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "SST = np.sum((data - grand_mean) ** 2)\n",
    "\n",
    "# Calculate the group means\n",
    "mean_A = np.mean(group_A)\n",
    "mean_B = np.mean(group_B)\n",
    "mean_C = np.mean(group_C)\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "n_per_group = len(group_A)  # Assuming all groups have the same sample size\n",
    "SSE = n_per_group * ((mean_A - grand_mean) ** 2 +\n",
    "                     (mean_B - grand_mean) ** 2 +\n",
    "                     (mean_C - grand_mean) ** 2)\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "# Degrees of freedom\n",
    "df_between = 2  # Number of groups minus 1\n",
    "df_within = n_per_group * 3 - 3  # Total number of observations minus the number of groups\n",
    "\n",
    "# Calculate the Mean Squares (MS) for between and within groups\n",
    "MS_between = SSE / df_between\n",
    "MS_within = SSR / df_within\n",
    "\n",
    "# Calculate the F-statistic\n",
    "F_statistic = MS_between / MS_within\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = 1 - stats.f.cdf(F_statistic, df_between, df_within)\n",
    "\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)\n",
    "print(\"F-statistic:\", F_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f61c464",
   "metadata": {},
   "source": [
    "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802f0eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect A: 48.16666666666673\n",
      "Main Effect B: 14.083333333333368\n",
      "Interaction Effect AB: 0.08333333333333418\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'A': ['A1', 'A2', 'A1', 'A2', 'A1', 'A2'],\n",
    "        'B': ['B1', 'B1', 'B2', 'B2', 'B1', 'B1'],\n",
    "        'Y': [10, 15, 12, 18, 8, 14]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Y ~ A + B + A:B', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effect\n",
    "main_effect_A = anova_table.loc['A', 'sum_sq'] / anova_table.loc['A', 'df']\n",
    "main_effect_B = anova_table.loc['B', 'sum_sq'] / anova_table.loc['B', 'df']\n",
    "interaction_effect = anova_table.loc['A:B', 'sum_sq'] / anova_table.loc['A:B', 'df']\n",
    "\n",
    "print(\"Main Effect A:\", main_effect_A)\n",
    "print(\"Main Effect B:\", main_effect_B)\n",
    "print(\"Interaction Effect AB:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed128ab",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b922a867",
   "metadata": {},
   "source": [
    "When conducting a one-way ANOVA, the F-statistic and p-value are used to assess whether there are significant differences in means between the groups. In your case, you obtained an F-statistic of 5.23 and a p-value of 0.02. Here's how to interpret these results:\n",
    "\n",
    "F-Statistic: The F-statistic measures the ratio of the variation between group means to the variation within groups. In other words, it tells you whether the differences between group means are larger than what you would expect by random chance.\n",
    "\n",
    "P-Value: The p-value is the probability of observing an F-statistic as extreme as the one obtained if there were no real differences between the groups (i.e., if the null hypothesis were true). A small p-value indicates that the observed differences are unlikely to be due to random chance.\n",
    "\n",
    "Now, let's interpret the results:\n",
    "\n",
    "Null Hypothesis (H0): The null hypothesis typically states that there are no significant differences between the group means.\n",
    "\n",
    "Alternative Hypothesis (Ha): The alternative hypothesis (in this case) is that there are significant differences between at least two of the group means.\n",
    "\n",
    "Based on the F-statistic and p-value:\n",
    "\n",
    "P-Value < Alpha (0.05): Since the p-value (0.02) is less than the chosen significance level (alpha) of 0.05 (a common threshold), you can conclude that there is evidence to reject the null hypothesis.\n",
    "\n",
    "Conclusion: Therefore, you can conclude that there are statistically significant differences between at least two of the groups in your study.\n",
    "\n",
    "Post-hoc Tests: If your ANOVA involves more than two groups, it's common practice to follow up with post-hoc tests (e.g., Tukey's HSD, Bonferroni) to determine which specific groups differ from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597620f",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6728ef",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is a critical aspect of data analysis because missing data can bias the results and reduce the power of your statistical test. There are various methods to handle missing data in repeated measures ANOVA, and the choice of method can have different consequences. Here are some common approaches to dealing with missing data:\n",
    "\n",
    "Listwise Deletion (Complete Case Analysis): In this approach, any subject with missing data on any of the measurements is excluded from the analysis. This is the simplest method but can result in a significant loss of data and reduced statistical power.\n",
    "\n",
    "Consequences:\n",
    "\n",
    "Reduced sample size and statistical power.\n",
    "Potential bias if the missing data are not missing completely at random (MCAR).\n",
    "Pairwise Deletion: In this approach, subjects with missing data on specific measurements are excluded only from the calculations involving those measurements. This allows you to retain more data points for each analysis but can lead to uneven sample sizes for different comparisons.\n",
    "\n",
    "Consequences:\n",
    "\n",
    "Retains more data than listwise deletion.\n",
    "Uneven sample sizes may affect the interpretation of results.\n",
    "Imputation Methods:\n",
    "\n",
    "Mean Imputation: Missing values are replaced with the mean of the observed values for that variable.\n",
    "Regression Imputation: Missing values are predicted based on other variables using regression.\n",
    "Multiple Imputation: Multiple datasets with imputed values are generated, and analyses are performed on each dataset. The results are then combined to account for uncertainty due to imputation.\n",
    "Consequences:\n",
    "\n",
    "Preserves sample size and statistical power.\n",
    "Assumes that the missing data mechanism is ignorable and correctly models the relationship between variables.\n",
    "Last Observation Carried Forward (LOCF) or Next Observation Carried Backward (NOCB): In longitudinal studies, the most recent observed value before the missing data point is carried forward or the next observed value is carried backward to replace the missing value.\n",
    "\n",
    "Consequences:\n",
    "\n",
    "May not be appropriate if the assumption that the last or next observation is a good estimate is violated.\n",
    "Can introduce bias if there are systematic changes in the data.\n",
    "Missing Data as a Level: Treat missing data as a separate level or category within the repeated measures factor. This approach allows you to include subjects with missing data in the analysis while explicitly accounting for the missing data pattern.\n",
    "\n",
    "Consequences:\n",
    "\n",
    "Preserves sample size but may not account for the missing data mechanism.\n",
    "The choice of method depends on several factors, including the nature of the data, the reasons for missingness, and the assumptions you are willing to make about the missing data mechanism. It's essential to carefully consider the potential consequences of each method and conduct sensitivity analyses to assess the robustness of your results to different missing data strategies. Multiple imputation is often recommended when possible, as it provides a principled way to handle missing data while accounting for uncertainty. However, it requires careful consideration of the imputation model and the missing data mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19dc8d9",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a640b007",
   "metadata": {},
   "source": [
    "Post-hoc tests are statistical procedures used after an Analysis of Variance (ANOVA) to make pairwise comparisons between groups or conditions when the ANOVA indicates that there are significant differences among groups. They help identify which specific group(s) differ from each other. Several common post-hoc tests are used, and the choice of which one to use depends on the design of your study and the assumptions you're willing to make. Here are some common post-hoc tests and when to use them:\n",
    "\n",
    "Tukey's Honestly Significant Difference (Tukey's HSD):\n",
    "\n",
    "When to use: Tukey's HSD is a conservative post-hoc test that is suitable when you have a balanced design (equal sample sizes in all groups) and you want to control the familywise error rate at a certain level (e.g., 0.05). It is a good choice when you have multiple groups and want to compare all possible pairs.\n",
    "Example: You conduct an ANOVA to compare the effectiveness of four different drugs on blood pressure, and the ANOVA indicates a significant difference. Tukey's HSD can be used to determine which pairs of drugs are significantly different.\n",
    "Bonferroni Correction:\n",
    "\n",
    "When to use: The Bonferroni correction is a conservative method used when you have a large number of pairwise comparisons and want to control the familywise error rate. It is suitable when you want to maintain a low overall Type I error rate.\n",
    "Example: You are comparing the performance of multiple products (e.g., 10 different brands of smartphones) in terms of battery life. A Bonferroni correction can be applied to adjust the significance level for the pairwise comparisons to control for multiple testing.\n",
    "Duncan's Multiple Range Test (MRT):\n",
    "\n",
    "When to use: Duncan's MRT is a less conservative post-hoc test suitable for comparing group means when you have a balanced design and want to identify homogeneous subsets of groups. It is helpful for ranking groups into distinct subsets based on their means.\n",
    "Example: You perform an ANOVA to analyze the yield of different types of crops under various fertilizer treatments. If the ANOVA shows a significant difference, Duncan's MRT can be used to group the fertilizers into subsets based on their effectiveness.\n",
    "Scheffé's Test:\n",
    "\n",
    "When to use: Scheffé's test is a conservative post-hoc test that can be used with both balanced and unbalanced designs. It is suitable when you want to control the familywise error rate in situations where other tests might be too liberal.\n",
    "Example: You conduct an ANOVA to examine the impact of three different teaching methods on student test scores. If the ANOVA indicates significant differences, Scheffé's test can be used to compare pairs of teaching methods while controlling the overall Type I error rate.\n",
    "Games-Howell Test:\n",
    "\n",
    "When to use: The Games-Howell test is a post-hoc test designed for situations where the assumption of equal variances is not met (heteroscedasticity). It is appropriate when the variances between groups are not equal.\n",
    "Example: You perform an ANOVA to compare the salaries of employees in different departments of a company. If the assumption of equal variances is violated, the Games-Howell test can be used for pairwise comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971670e2",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a19513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. There is a significant difference in mean weight loss among the three diets (F-statistic = 525.62, p-value = 0.0000).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for weight loss in each diet group\n",
    "diet_A = np.array([2.3, 1.8, 3.2, 2.7, 3.5, 2.1, 2.9, 3.0, 2.8, 3.1, \n",
    "                   2.4, 2.5, 2.2, 3.3, 2.6, 2.0, 3.7, 2.8, 2.6, 3.2,\n",
    "                   2.9, 2.8, 2.4, 3.1, 2.7, 3.0, 2.6, 2.8, 2.2, 3.3,\n",
    "                   2.4, 2.9, 2.7, 2.5, 3.2, 2.8, 3.1, 2.1, 3.5, 2.6,\n",
    "                   2.8, 3.2, 2.4, 3.0, 2.7, 2.5, 2.9, 2.2, 3.3])\n",
    "\n",
    "diet_B = np.array([1.5, 1.4, 1.9, 1.8, 1.7, 1.3, 1.6, 2.0, 1.4, 1.7, \n",
    "                   1.9, 1.6, 1.8, 1.3, 1.7, 1.5, 1.8, 1.6, 1.9, 1.4,\n",
    "                   1.7, 1.5, 1.8, 1.9, 1.6, 1.4, 1.7, 1.5, 1.8, 1.6,\n",
    "                   1.9, 1.6, 1.7, 1.8, 1.4, 1.5, 1.9, 1.6, 1.7, 1.8,\n",
    "                   1.3, 1.4, 1.6, 1.8, 1.9, 1.7, 1.5, 1.4, 1.6, 1.8])\n",
    "\n",
    "diet_C = np.array([3.8, 3.5, 4.0, 3.3, 3.7, 3.9, 3.6, 3.4, 3.2, 3.5, \n",
    "                   4.1, 3.7, 3.9, 3.3, 3.6, 3.8, 3.2, 3.4, 3.7, 3.5,\n",
    "                   4.0, 3.3, 3.7, 3.9, 3.6, 3.8, 3.2, 3.4, 3.7, 3.5,\n",
    "                   4.0, 3.3, 3.7, 3.9, 3.6, 3.8, 3.2, 3.4, 3.7, 3.5,\n",
    "                   4.0, 3.3, 3.7, 3.9, 3.6, 3.8, 3.2, 3.4, 3.7, 3.5])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set the significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"Reject the null hypothesis. There is a significant difference in mean weight loss among the three diets (F-statistic = {f_statistic:.2f}, p-value = {p_value:.4f}).\")\n",
    "else:\n",
    "    print(f\"Fail to reject the null hypothesis. There is no significant difference in mean weight loss among the three diets (F-statistic = {f_statistic:.2f}, p-value = {p_value:.4f}).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b4b82",
   "metadata": {},
   "source": [
    "# Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa61c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis for the main effect of Software (F-statistic = 63.85, p-value = 0.0000).\n",
      "No significant main effect of Experience (F-statistic = 1.52, p-value = 0.2299).\n",
      "No significant interaction effect (F-statistic = 0.89, p-value = 0.4226).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Software': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'A', 'A', 'A'],\n",
    "    'Experience': ['Novice', 'Experienced', 'Experienced', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Experienced', 'Experienced'],\n",
    "    'Time': [22, 19, 18, 25, 24, 23, 17, 16, 18, 20, 18, 17, 28, 26, 27, 15, 16, 14, 21, 19, 20, 30, 29, 31, 13, 15, 14, 24, 22, 23]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Time ~ Software * Experience', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effect\n",
    "main_effect_software = anova_table.loc['Software', 'sum_sq'] / anova_table.loc['Software', 'df']\n",
    "main_effect_experience = anova_table.loc['Experience', 'sum_sq'] / anova_table.loc['Experience', 'df']\n",
    "interaction_effect = anova_table.loc['Software:Experience', 'sum_sq'] / anova_table.loc['Software:Experience', 'df']\n",
    "\n",
    "# Report the results\n",
    "alpha = 0.05  # Set the significance level\n",
    "\n",
    "if anova_table['PR(>F)']['Software'] < alpha:\n",
    "    print(f\"Reject the null hypothesis for the main effect of Software (F-statistic = {anova_table['F']['Software']:.2f}, p-value = {anova_table['PR(>F)']['Software']:.4f}).\")\n",
    "else:\n",
    "    print(f\"No significant main effect of Software (F-statistic = {anova_table['F']['Software']:.2f}, p-value = {anova_table['PR(>F)']['Software']:.4f}).\")\n",
    "\n",
    "if anova_table['PR(>F)']['Experience'] < alpha:\n",
    "    print(f\"Reject the null hypothesis for the main effect of Experience (F-statistic = {anova_table['F']['Experience']:.2f}, p-value = {anova_table['PR(>F)']['Experience']:.4f}).\")\n",
    "else:\n",
    "    print(f\"No significant main effect of Experience (F-statistic = {anova_table['F']['Experience']:.2f}, p-value = {anova_table['PR(>F)']['Experience']:.4f}).\")\n",
    "\n",
    "if anova_table['PR(>F)']['Software:Experience'] < alpha:\n",
    "    print(f\"Reject the null hypothesis for the interaction effect (F-statistic = {anova_table['F']['Software:Experience']:.2f}, p-value = {anova_table['PR(>F)']['Software:Experience']:.4f}).\")\n",
    "else:\n",
    "    print(f\"No significant interaction effect (F-statistic = {anova_table['F']['Software:Experience']:.2f}, p-value = {anova_table['PR(>F)']['Software:Experience']:.4f}).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4fdbbd",
   "metadata": {},
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c27a29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. There is a significant difference in test scores between the control and experimental groups (t-statistic = -10.56, p-value = 0.0000).\n",
      "Perform a post-hoc test to determine which group(s) differ significantly from each other.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Hypothetical test scores for the control group and experimental group\n",
    "control_scores = np.array([85, 88, 90, 78, 92, 86, 79, 89, 82, 87,\n",
    "                           83, 88, 84, 85, 81, 90, 79, 88, 86, 82,\n",
    "                           80, 84, 89, 85, 87, 91, 80, 83, 89, 88])\n",
    "\n",
    "experimental_scores = np.array([92, 94, 91, 95, 93, 96, 90, 93, 91, 97,\n",
    "                                94, 92, 95, 94, 92, 96, 93, 94, 91, 97,\n",
    "                                95, 93, 96, 92, 98, 91, 95, 93, 97, 96])\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Set the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < alpha:\n",
    "    print(f\"Reject the null hypothesis. There is a significant difference in test scores between the control and experimental groups (t-statistic = {t_statistic:.2f}, p-value = {p_value:.4f}).\")\n",
    "else:\n",
    "    print(f\"Fail to reject the null hypothesis. There is no significant difference in test scores between the control and experimental groups (t-statistic = {t_statistic:.2f}, p-value = {p_value:.4f}).\")\n",
    "\n",
    "# If the results are significant, perform a post-hoc test (e.g., Tukey's HSD, Bonferroni) to compare group means.\n",
    "if p_value < alpha:\n",
    "    print(\"Perform a post-hoc test to determine which group(s) differ significantly from each other.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc5a31",
   "metadata": {},
   "source": [
    "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a posthoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f0d06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. There is a significant difference in sales between the three stores (F-statistic = 94.67, p-value = 0.0000).\n",
      "Perform a post-hoc test to determine which store(s) differ significantly from each other.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Hypothetical daily sales data for Store A, Store B, and Store C\n",
    "store_A_sales = np.array([100, 110, 95, 105, 98, 120, 115, 102, 110, 112,\n",
    "                          105, 108, 100, 110, 95, 105, 98, 120, 115, 102,\n",
    "                          110, 112, 105, 108, 100, 110, 95, 105, 98, 120])\n",
    "\n",
    "store_B_sales = np.array([90, 92, 88, 85, 92, 100, 105, 98, 94, 89,\n",
    "                          90, 92, 88, 85, 92, 100, 105, 98, 94, 89,\n",
    "                          90, 92, 88, 85, 92, 100, 105, 98, 94, 89])\n",
    "\n",
    "store_C_sales = np.array([80, 82, 78, 75, 82, 90, 95, 88, 85, 80,\n",
    "                          80, 82, 78, 75, 82, 90, 95, 88, 85, 80,\n",
    "                          80, 82, 78, 75, 82, 90, 95, 88, 85, 80])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(store_A_sales, store_B_sales, store_C_sales)\n",
    "\n",
    "# Set the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < alpha:\n",
    "    print(f\"Reject the null hypothesis. There is a significant difference in sales between the three stores (F-statistic = {f_statistic:.2f}, p-value = {p_value:.4f}).\")\n",
    "else:\n",
    "    print(f\"Fail to reject the null hypothesis. There is no significant difference in sales between the three stores (F-statistic = {f_statistic:.2f}, p-value = {p_value:.4f}).\")\n",
    "\n",
    "# If the results are significant, perform a post-hoc test (e.g., Tukey's HSD, Bonferroni) to compare store means.\n",
    "if p_value < alpha:\n",
    "    print(\"Perform a post-hoc test to determine which store(s) differ significantly from each other.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d46590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39a39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
